# å¯¼å…¥æ‰€éœ€åº“
import streamlit as st
from streamlit_drawable_canvas import st_canvas
import cv2
import numpy as np
from PIL import Image
import os
from datetime import datetime
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline
import glob
import time

# è®¾ç½® Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="Advanced Personal AI Image & Video Tool",
    layout="wide",
    page_icon="ğŸ¥"
)

# å…¨å±€æ ‡å¿—ï¼Œç”¨äºå–æ¶ˆä»»åŠ¡
if 'cancel_task' not in st.session_state:
    st.session_state.cancel_task = False
if 'continue_task' not in st.session_state:
    st.session_state.continue_task = False

# è‡ªå®šä¹‰ CSSï¼šå¡ç‰‡å¼å¸ƒå±€ã€åŠ¨ç”»æŒ‰é’®
st.markdown(
    """
    <style>
    .card {
        background-color: #f9f9f9;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        margin-bottom: 20px;
        transition: all 0.3s ease;
    }
    .card:hover {
        box-shadow: 0 8px 16px rgba(0,0,0,0.2);
        transform: translateY(-5px);
    }
    .custom-button {
        display: inline-block;
        padding: 12px 24px;
        font-size: 16px;
        font-weight: bold;
        color: white;
        background: linear-gradient(45deg, #4CAF50, #45a049);
        border: none;
        border-radius: 10px;
        cursor: pointer;
        transition: all 0.3s ease;
        transform: scale(1);
    }
    .custom-button:hover {
        transform: scale(1.1);
        box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    }
    .cancel-button {
        background: linear-gradient(45deg, #f44336, #d32f2f);
    }
    .stButton>button {
        background: linear-gradient(45deg, #2196F3, #21CBF3);
        color: white;
        border-radius: 10px;
    }
    .history-item {
        margin: 5px 0;
        font-size: 14px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# åˆ›å»ºé»˜è®¤æ–‡ä»¶å¤¹
if not os.path.exists("input"):
    os.makedirs("input")
if not os.path.exists("output"):
    os.makedirs("output")


# åˆå§‹åŒ– Stable Diffusion æ¨¡å‹
@st.cache_resource
def load_diffusion_model(model_type="generate"):
    """åŠ è½½ Stable Diffusion æ¨¡å‹ï¼Œä¼˜å…ˆ GPU"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        if model_type == "inpaint":
            pipe = StableDiffusionInpaintPipeline.from_pretrained(
                "runwayml/stable-diffusion-inpainting",
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                use_auth_token=False
            )
        else:
            pipe = StableDiffusionPipeline.from_pretrained(
                "runwayml/stable-diffusion-v1-5",
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                use_auth_token=False
            )
        pipe = pipe.to(device)
        if device == "cpu":
            pipe.enable_attention_slicing()
        st.success(f"ğŸ¨ Stable Diffusion {'Inpainting' if model_type == 'inpaint' else 'Generate'} åŠ è½½æˆåŠŸï¼ˆ{device}ï¼‰")
        return pipe
    except Exception as e:
        st.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None


# åˆ†æå›¾åƒ/è§†é¢‘å†…å®¹
def analyze_content(file, file_type):
    """åˆ†æå›¾åƒ/è§†é¢‘å†…å®¹ï¼Œæå–ä¸»è‰²è°ƒç­‰ç‰¹å¾"""
    try:
        if file_type == "å›¾åƒ":
            image = Image.open(file)
            image_np = np.array(image)
            mean_color = np.mean(image_np, axis=(0, 1))
            return f"dominant colors RGB({int(mean_color[0])},{int(mean_color[1])},{int(mean_color[2])})"
        else:
            cap = cv2.VideoCapture(os.path.join(st.session_state.upload_path, file.name))
            ret, frame = cap.read()
            cap.release()
            if not ret:
                return "dynamic scene"
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            mean_color = np.mean(frame_rgb, axis=(0, 1))
            return f"dominant colors RGB({int(mean_color[0])},{int(mean_color[1])},{int(mean_color[2])})"
    except Exception as e:
        return "unknown content"


# æ™ºèƒ½æ‰©å†™æè¿°
def expand_prompt(prompt, duration=None, file=None, file_type=None):
    """æ ¹æ®æ—¶é•¿å’Œå†…å®¹åŠ¨æ€æ‰©å†™æè¿°"""
    try:
        if not prompt.strip():
            return "A beautiful scene, highly detailed, cinematic"

        base_desc = prompt
        content_desc = ""
        if file and file_type:
            content_desc = analyze_content(file, file_type)

        target_words = 100 if not duration else int(30 * duration)
        additions = [
            f", highly detailed, vibrant colors, soft lighting, {content_desc}",
            f", cinematic style, realistic textures, 4K resolution, {content_desc}",
            f", in a serene environment, vivid details, dreamy atmosphere, {content_desc}"
        ]
        import random
        expanded = base_desc + random.choice(additions)

        if duration and duration > 10:
            extra_details = [
                ", with intricate patterns and subtle movements",
                ", featuring dynamic lighting and rich textures",
                ", evolving with gentle transitions and vivid contrasts"
            ]
            for _ in range(int(duration / 5)):
                expanded += random.choice(extra_details)

        target_chars = target_words * 5
        if len(expanded) > target_chars:
            expanded = expanded[:target_chars] + "..."

        return expanded
    except Exception as e:
        st.error(f"æ‰©å†™é”™è¯¯: {e}")
        return prompt


# æè¿°ç”Ÿæˆå›¾åƒ
def generate_image_from_text(prompt, pipe):
    """ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾åƒ"""
    try:
        if pipe is None:
            st.error("æ¨¡å‹æœªåŠ è½½ï¼")
            return None
        if st.session_state.cancel_task:
            st.warning("ä»»åŠ¡å·²å–æ¶ˆï¼")
            return None
        with torch.no_grad():
            image = pipe(prompt, num_inference_steps=20, guidance_scale=7.5).images[0]
        return image
    except Exception as e:
        st.error(f"ç”Ÿæˆå›¾åƒé”™è¯¯: {e}")
        return None


# å›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘
def generate_video_from_image_and_text(image, prompt, pipe, duration, fps=24):
    """åŸºäºå›¾åƒå’Œæè¿°ç”Ÿæˆè§†é¢‘"""
    try:
        if pipe is None:
            st.error("æ¨¡å‹æœªåŠ è½½ï¼")
            return None
        frames = []
        num_frames = int(duration * fps)
        progress = st.progress(0)

        # åˆå§‹å¸§
        init_image = image.resize((512, 512))  # Stable Diffusion è¦æ±‚ 512x512
        mask = np.zeros((512, 512), dtype=np.uint8)  # å…¨å›¾ inpainting
        frames.append(np.array(init_image.convert("RGB")))

        # ç”Ÿæˆåç»­å¸§
        for i in range(1, num_frames):
            if st.session_state.cancel_task:
                st.warning("è§†é¢‘ç”Ÿæˆå·²å–æ¶ˆï¼")
                return None
            frame_prompt = f"{prompt}, frame {i}, subtle motion"
            with torch.no_grad():
                frame = pipe(
                    prompt=frame_prompt,
                    init_image=init_image,
                    mask_image=Image.fromarray(mask),
                    strength=0.3,  # è½»å¾®ä¿®æ”¹åˆå§‹å›¾åƒ
                    num_inference_steps=20
                ).images[0]
            frames.append(np.array(frame.convert("RGB")))
            progress.progress((i + 1) / num_frames)

        height, width = frames[0].shape[:2]
        output_path = os.path.join(st.session_state.output_path,
                                   f"generated_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        for frame in frames:
            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
        out.release()
        return output_path
    except Exception as e:
        st.error(f"ç”Ÿæˆè§†é¢‘é”™è¯¯: {e}")
        return None


# ç”Ÿæˆè§†é¢‘ï¼ˆæè¿°ï¼‰
def generate_video_from_text(prompt, pipe, duration, fps=24):
    """ç”Ÿæˆå›¾åƒåºåˆ—å¹¶åˆæˆä¸ºè§†é¢‘"""
    try:
        if pipe is None:
            st.error("æ¨¡å‹æœªåŠ è½½ï¼")
            return None
        frames = []
        num_frames = int(duration * fps)
        progress = st.progress(0)
        for i in range(num_frames):
            if st.session_state.cancel_task:
                st.warning("è§†é¢‘ç”Ÿæˆå·²å–æ¶ˆï¼")
                return None
            frame_prompt = f"{prompt}, frame {i}"
            image = generate_image_from_text(frame_prompt, pipe)
            if image:
                frames.append(np.array(image.convert("RGB")))
            progress.progress((i + 1) / num_frames)

        height, width = frames[0].shape[:2]
        output_path = os.path.join(st.session_state.output_path,
                                   f"generated_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        for frame in frames:
            out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
        out.release()
        return output_path
    except Exception as e:
        st.error(f"ç”Ÿæˆè§†é¢‘é”™è¯¯: {e}")
        return None


# å»é™¤å›¾åƒæ°´å°
def remove_watermark_image(image, mask, inpaint_radius=3):
    """ä½¿ç”¨ OpenCV inpainting å»é™¤å›¾åƒæ°´å°"""
    try:
        result = cv2.inpaint(image, mask, inpaintRadius=inpaint_radius, flags=cv2.INPAINT_TELEA)
        return result
    except Exception as e:
        st.error(f"å›¾åƒå»æ°´å°é”™è¯¯: {e}")
        return image


# å»é™¤è§†é¢‘æ°´å°
def remove_watermark_video(video_path, mask, output_path, inpaint_radius=3, max_duration=None):
    """é€å¸§å»é™¤è§†é¢‘æ°´å°ï¼Œæ”¯æŒæŒ‡å®šæ—¶é•¿"""
    try:
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError("æ— æ³•æ‰“å¼€è§†é¢‘")

        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if max_duration:
            max_frames = int(max_duration * fps)
            total_frames = min(total_frames, max_frames)

        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        progress = st.progress(0)
        frame_count = 0

        while cap.isOpened() and frame_count < total_frames:
            if st.session_state.cancel_task:
                cap.release()
                out.release()
                st.warning("è§†é¢‘å¤„ç†å·²å–æ¶ˆï¼")
                return None
            ret, frame = cap.read()
            if not ret:
                break
            processed_frame = remove_watermark_image(frame, mask, inpaint_radius)
            out.write(processed_frame)
            frame_count += 1
            progress.progress(min(frame_count / total_frames, 1.0))

        cap.release()
        out.release()
        return output_path
    except Exception as e:
        st.error(f"è§†é¢‘å»æ°´å°é”™è¯¯: {e}")
        return None


# é¢„è®¡æ—¶é—´ä¼°ç®—
def estimate_time(task, duration=None, frame_count=None):
    """ä¼°ç®—ä»»åŠ¡æ—¶é—´ï¼ˆç§’ï¼‰"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    if task == "image":
        return 10 if device == "cuda" else 120
    elif task in ["video_generate", "video_from_image"]:
        image_time = 10 if device == "cuda" else 120
        return image_time * duration * 24
    elif task == "video_remove":
        frame_time = 0.05 if device == "cuda" else 0.1
        return frame_count * frame_time


# Streamlit ç•Œé¢
st.title("ğŸ¥ é«˜çº§ä¸ªäºº AI å›¾åƒä¸è§†é¢‘å¤„ç†å·¥å…·")
st.markdown("æœ¬åœ°è¿è¡Œï¼Œå¸¦å¡ç‰‡å¼ç•Œé¢ã€åŠ¨ç”»æŒ‰é’®å’Œäº¤äº’å¼ç”»å¸ƒï¼Œæ”¯æŒå›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘ã€è‡ªç”±æ—¶é•¿å’ŒåŠ¨æ€æ‰©å†™ï¼")
st.markdown(
    f"ğŸŒŸ è¿è¡Œäº {'GPU' if torch.cuda.is_available() else 'CPU'} | å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# å¯¼èˆªæ 
st.sidebar.header("ğŸš€ å¯¼èˆª")
option = st.sidebar.radio(
    "é€‰æ‹©åŠŸèƒ½",
    ["ğŸ“· æè¿°ç”Ÿæˆå›¾åƒ", "ğŸ¬ æè¿°ç”Ÿæˆè§†é¢‘", "ğŸ–¼ï¸ å›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘", "âœï¸ æ™ºèƒ½æ‰©å†™æè¿°", "ğŸ§¹ æ¶ˆé™¤å›¾åƒ/è§†é¢‘æ°´å°"]
)

# è·¯å¾„è®¾ç½®
with st.sidebar.expander("ğŸ“ æ–‡ä»¶è·¯å¾„è®¾ç½®"):
    upload_path = st.text_input("ä¸Šä¼ æ–‡ä»¶å¤¹è·¯å¾„", value="input")
    output_path = st.text_input("ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„", value="output")
    st.session_state.upload_path = upload_path
    st.session_state.output_path = output_path
    if not os.path.exists(upload_path):
        os.makedirs(upload_path)
    if not os.path.exists(output_path):
        os.makedirs(output_path)

# å†å²æ–‡ä»¶
with st.sidebar.expander("ğŸ“œ å¤„ç†å†å²"):
    history_files = glob.glob(os.path.join(output_path, "*"))
    if history_files:
        st.write("æœ€è¿‘ç”Ÿæˆ/å¤„ç†çš„æ–‡ä»¶ï¼š")
        for f in history_files[:5]:
            st.markdown(f'<p class="history-item">{os.path.basename(f)}</p>', unsafe_allow_html=True)
            st.download_button(
                label=f"â¬‡ï¸ ä¸‹è½½ {os.path.basename(f)}",
                data=open(f, "rb").read(),
                file_name=os.path.basename(f),
                mime="image/png" if f.endswith(".png") else "video/mp4"
            )
    else:
        st.write("æš‚æ— å†å²æ–‡ä»¶")

# åŒåˆ—å¸ƒå±€
col1, col2 = st.columns([1, 1])

# åŠŸèƒ½ 1ï¼šæè¿°ç”Ÿæˆå›¾åƒ
if option == "ğŸ“· æè¿°ç”Ÿæˆå›¾åƒ":
    with col1:
        with st.container():
            st.markdown('<div class="card"><h3>ğŸ“· æè¿°ç”Ÿæˆå›¾åƒ</h3>', unsafe_allow_html=True)
            prompt = st.text_area("è¾“å…¥æè¿°ï¼ˆå¦‚ 'å¤•é˜³ä¸‹çš„æ¹–'ï¼‰", value="")
            uploaded_file = st.file_uploader("ä¸Šä¼ å‚è€ƒå›¾åƒï¼ˆå¯é€‰ï¼‰", type=["jpg", "png", "jpeg"])
            if st.checkbox("âœ¨ æ™ºèƒ½æ‰©å†™æè¿°"):
                prompt = expand_prompt(prompt, file=uploaded_file, file_type="å›¾åƒ")
                st.write("æ‰©å†™åçš„æè¿°ï¼š", prompt)
            st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown('<div class="card">', unsafe_allow_html=True)
            estimated_time = estimate_time("image")
            st.write(f"é¢„è®¡ç”Ÿæˆæ—¶é—´ï¼šçº¦ {estimated_time} ç§’")
            if st.button("æ˜¯å¦ç»§ç»­ï¼Ÿ"):
                st.session_state.continue_task = True
            if st.session_state.get("continue_task", False) and (st.markdown(
                    '<button class="custom-button">ğŸ¨ ç”Ÿæˆå›¾åƒ</button>',
                    unsafe_allow_html=True
            ) or st.button("ç”Ÿæˆå›¾åƒï¼ˆå¤‡ç”¨ï¼‰")):
                st.session_state.cancel_task = False
                if st.markdown(
                        '<button class="custom-button cancel-button">âŒ å–æ¶ˆç”Ÿæˆ</button>',
                        unsafe_allow_html=True
                ) or st.button("å–æ¶ˆç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰"):
                    st.session_state.cancel_task = True
                if not prompt:
                    st.error("è¯·è¾“å…¥æè¿°ï¼")
                else:
                    with st.spinner("åŠ è½½æ¨¡å‹..."):
                        pipe = load_diffusion_model("generate")
                    if pipe:
                        with st.spinner("ç”Ÿæˆå›¾åƒ..."):
                            image = generate_image_from_text(prompt, pipe)
                        if image:
                            st.image(image, caption="ç”Ÿæˆçš„å›¾åƒ", use_column_width=True)
                            output_file = os.path.join(output_path,
                                                       f"image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
                            image.save(output_file)
                            st.download_button(
                                label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„å›¾åƒ",
                                data=open(output_file, "rb").read(),
                                file_name=os.path.basename(output_file),
                                mime="image/png"
                            )
            st.markdown('</div>', unsafe_allow_html=True)

# åŠŸèƒ½ 2ï¼šæè¿°ç”Ÿæˆè§†é¢‘
elif option == "ğŸ¬ æè¿°ç”Ÿæˆè§†é¢‘":
    with col1:
        with st.container():
            st.markdown('<div class="card"><h3>ğŸ¬ æè¿°ç”Ÿæˆè§†é¢‘</h3>', unsafe_allow_html=True)
            prompt = st.text_area("è¾“å…¥æè¿°ï¼ˆå¦‚ 'æ˜Ÿç©ºä¸‹çš„é£èˆ¹'ï¼‰", value="")
            duration_input = st.text_input("è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œä¾‹ï¼š5.5ï¼‰", value="5")
            try:
                duration = float(duration_input)
                if duration <= 0:
                    raise ValueError("æ—¶é•¿å¿…é¡»ä¸ºæ­£æ•°")
            except ValueError:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆæ—¶é•¿ï¼ˆæ­£æ•°ï¼‰ï¼")
                duration = None
            uploaded_file = st.file_uploader("ä¸Šä¼ å‚è€ƒå›¾åƒ/è§†é¢‘ï¼ˆå¯é€‰ï¼‰", type=["jpg", "png", "jpeg", "mp4", "avi"])
            if st.checkbox("âœ¨ æ™ºèƒ½æ‰©å†™æè¿°"):
                prompt = expand_prompt(prompt, duration, uploaded_file,
                                       "è§†é¢‘" if uploaded_file and uploaded_file.name.endswith(
                                           (".mp4", ".avi")) else "å›¾åƒ")
                st.write("æ‰©å†™åçš„æè¿°ï¼š", prompt)
            st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown('<div class="card">', unsafe_allow_html=True)
            if duration:
                estimated_time = estimate_time("video_generate", duration)
                st.write(f"é¢„è®¡ç”Ÿæˆæ—¶é—´ï¼šçº¦ {estimated_time} ç§’")
                if st.button("æ˜¯å¦ç»§ç»­ï¼Ÿ"):
                    st.session_state.continue_task = True
                if st.session_state.get("continue_task", False) and (st.markdown(
                        '<button class="custom-button">ğŸ¬ ç”Ÿæˆè§†é¢‘</button>',
                        unsafe_allow_html=True
                ) or st.button("ç”Ÿæˆè§†é¢‘ï¼ˆå¤‡ç”¨ï¼‰")):
                    st.session_state.cancel_task = False
                    if st.markdown(
                            '<button class="custom-button cancel-button">âŒ å–æ¶ˆç”Ÿæˆ</button>',
                            unsafe_allow_html=True
                    ) or st.button("å–æ¶ˆç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰"):
                        st.session_state.cancel_task = True
                    if not prompt:
                        st.error("è¯·è¾“å…¥æè¿°ï¼")
                    else:
                        with st.spinner("åŠ è½½æ¨¡å‹..."):
                            pipe = load_diffusion_model("generate")
                        if pipe:
                            with st.spinner("ç”Ÿæˆè§†é¢‘..."):
                                video_path = generate_video_from_text(prompt, pipe, duration)
                            if video_path:
                                st.video(video_path)
                                st.download_button(
                                    label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘",
                                    data=open(video_path, "rb").read(),
                                    file_name=os.path.basename(video_path),
                                    mime="video/mp4"
                                )
            st.markdown('</div>', unsafe_allow_html=True)

# åŠŸèƒ½ 3ï¼šå›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘
elif option == "ğŸ–¼ï¸ å›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘":
    with col1:
        with st.container():
            st.markdown('<div class="card"><h3>ğŸ–¼ï¸ å›¾åƒ+æè¿°ç”Ÿæˆè§†é¢‘</h3>', unsafe_allow_html=True)
            prompt = st.text_area("è¾“å…¥æè¿°ï¼ˆå¦‚ 'é£èˆ¹èµ·é£'ï¼‰", value="")
            uploaded_file = st.file_uploader("ä¸Šä¼ åˆå§‹å›¾åƒ", type=["jpg", "png", "jpeg"])
            duration_input = st.text_input("è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œä¾‹ï¼š5.5ï¼‰", value="5")
            try:
                duration = float(duration_input)
                if duration <= 0:
                    raise ValueError("æ—¶é•¿å¿…é¡»ä¸ºæ­£æ•°")
            except ValueError:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆæ—¶é•¿ï¼ˆæ­£æ•°ï¼‰ï¼")
                duration = None
            if st.checkbox("âœ¨ æ™ºèƒ½æ‰©å†™æè¿°"):
                prompt = expand_prompt(prompt, duration, uploaded_file, "å›¾åƒ")
                st.write("æ‰©å†™åçš„æè¿°ï¼š", prompt)
            st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown('<div class="card">', unsafe_allow_html=True)
            if duration and uploaded_file:
                estimated_time = estimate_time("video_from_image", duration)
                st.write(f"é¢„è®¡ç”Ÿæˆæ—¶é—´ï¼šçº¦ {estimated_time} ç§’")
                if st.button("æ˜¯å¦ç»§ç»­ï¼Ÿ"):
                    st.session_state.continue_task = True
                if st.session_state.get("continue_task", False) and (st.markdown(
                        '<button class="custom-button">ğŸ¬ ç”Ÿæˆè§†é¢‘</button>',
                        unsafe_allow_html=True
                ) or st.button("ç”Ÿæˆè§†é¢‘ï¼ˆå¤‡ç”¨ï¼‰")):
                    st.session_state.cancel_task = False
                    if st.markdown(
                            '<button class="custom-button cancel-button">âŒ å–æ¶ˆç”Ÿæˆ</button>',
                            unsafe_allow_html=True
                    ) or st.button("å–æ¶ˆç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰"):
                        st.session_state.cancel_task = True
                    if not prompt:
                        st.error("è¯·è¾“å…¥æè¿°ï¼")
                    elif not uploaded_file:
                        st.error("è¯·ä¸Šä¼ åˆå§‹å›¾åƒï¼")
                    else:
                        with st.spinner("åŠ è½½æ¨¡å‹..."):
                            pipe = load_diffusion_model("inpaint")
                        if pipe:
                            with st.spinner("ç”Ÿæˆè§†é¢‘..."):
                                image = Image.open(uploaded_file)
                                video_path = generate_video_from_image_and_text(image, prompt, pipe, duration)
                            if video_path:
                                st.video(video_path)
                                st.download_button(
                                    label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘",
                                    data=open(video_path, "rb").read(),
                                    file_name=os.path.basename(video_path),
                                    mime="video/mp4"
                                )
            st.markdown('</div>', unsafe_allow_html=True)

# åŠŸèƒ½ 4ï¼šæ™ºèƒ½æ‰©å†™æè¿°
elif option == "âœï¸ æ™ºèƒ½æ‰©å†™æè¿°":
    with col1:
        with st.container():
            st.markdown('<div class="card"><h3>âœï¸ æ™ºèƒ½æ‰©å†™æè¿°</h3>', unsafe_allow_html=True)
            prompt = st.text_area("è¾“å…¥ç®€çŸ­æè¿°ï¼ˆå¦‚ 'çŒ«å’ª'ï¼‰", value="")
            duration_input = st.text_input("è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œä¾‹ï¼š5.5ï¼Œå¯é€‰ï¼‰", value="")
            try:
                duration = float(duration_input) if duration_input else None
                if duration is not None and duration <= 0:
                    raise ValueError("æ—¶é•¿å¿…é¡»ä¸ºæ­£æ•°")
            except ValueError:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆæ—¶é•¿ï¼ˆæ­£æ•°ï¼‰æˆ–ç•™ç©ºï¼")
                duration = None
            uploaded_file = st.file_uploader("ä¸Šä¼ å‚è€ƒå›¾åƒ/è§†é¢‘ï¼ˆå¯é€‰ï¼‰", type=["jpg", "png", "jpeg", "mp4", "avi"])
            st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown('<div class="card">', unsafe_allow_html=True)
            if st.markdown(
                    '<button class="custom-button">âœ¨ æ‰©å†™æè¿°</button>',
                    unsafe_allow_html=True
            ) or st.button("æ‰©å†™æè¿°ï¼ˆå¤‡ç”¨ï¼‰"):
                if prompt:
                    expanded_prompt = expand_prompt(
                        prompt,
                        duration,
                        uploaded_file,
                        "è§†é¢‘" if uploaded_file and uploaded_file.name.endswith((".mp4", ".avi")) else "å›¾åƒ"
                    )
                    st.write("æ‰©å†™ç»“æœï¼š", expanded_prompt)
                else:
                    st.error("è¯·è¾“å…¥æè¿°ï¼")
            st.markdown('</div>', unsafe_allow_html=True)

# åŠŸèƒ½ 5ï¼šæ¶ˆé™¤å›¾åƒ/è§†é¢‘æ°´å°
elif option == "ğŸ§¹ æ¶ˆé™¤å›¾åƒ/è§†é¢‘æ°´å°":
    with col1:
        with st.container():
            st.markdown('<div class="card"><h3>ğŸ§¹ æ¶ˆé™¤å›¾åƒ/è§†é¢‘æ°´å°</h3>', unsafe_allow_html=True)
            file_type = st.radio("æ–‡ä»¶ç±»å‹", ["å›¾åƒ", "è§†é¢‘"])
            uploaded_file = st.file_uploader(
                f"ä¸Šä¼ {file_type}",
                type=["jpg", "png", "jpeg"] if file_type == "å›¾åƒ" else ["mp4", "avi"],
                accept_multiple_files=False
            )
            if file_type == "è§†é¢‘":
                duration_input = st.text_input("å¤„ç†è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼Œä¾‹ï¼š5.5ï¼‰", value="10")
                try:
                    max_duration = float(duration_input)
                    if max_duration <= 0:
                        raise ValueError("æ—¶é•¿å¿…é¡»ä¸ºæ­£æ•°")
                except ValueError:
                    st.error("è¯·è¾“å…¥æœ‰æ•ˆæ—¶é•¿ï¼ˆæ­£æ•°ï¼‰ï¼")
                    max_duration = None
            else:
                max_duration = None
            stroke_width = st.slider("ğŸ–Œï¸ ç”»ç¬”ç²—ç»†", 1, 50, 10)
            stroke_color = st.color_picker("ğŸ¨ ç”»ç¬”é¢œè‰²", "#FFFFFF")
            inpaint_radius = st.slider("ğŸ› ï¸ è¡¥å…¨åŠå¾„", 1, 10, 3)
            if uploaded_file:
                if file_type == "å›¾åƒ":
                    image = Image.open(uploaded_file)
                    image_np = np.array(image)
                    image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                else:
                    cap = cv2.VideoCapture(os.path.join(upload_path, uploaded_file.name))
                    ret, frame = cap.read()
                    cap.release()
                    if not ret:
                        st.error("æ— æ³•è¯»å–è§†é¢‘å¸§ï¼")
                        image_np = None
                    else:
                        image_np = frame
                if image_np is not None:
                    st.write("ç»˜åˆ¶æ°´å°åŒºåŸŸï¼ˆç™½è‰²ï¼‰æˆ–æ“¦é™¤ï¼ˆé»‘è‰²æ©¡çš®ï¼‰")
                    canvas_result = st_canvas(
                        fill_color=stroke_color,
                        stroke_width=stroke_width,
                        stroke_color=stroke_color,
                        background_image=Image.fromarray(cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)),
                        height=min(image_np.shape[0], 600),
                        width=min(image_np.shape[1], 800),
                        drawing_mode="freedraw",
                        key="canvas"
                    )
            st.markdown('</div>', unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown('<div class="card">', unsafe_allow_html=True)
            if uploaded_file and max_duration is not None:
                estimated_time = estimate_time("image" if file_type == "å›¾åƒ" else "video_remove",
                                               frame_count=int(max_duration * 24) if file_type == "è§†é¢‘" else None)
                st.write(f"é¢„è®¡å¤„ç†æ—¶é—´ï¼šçº¦ {estimated_time} ç§’")
                if st.button("æ˜¯å¦ç»§ç»­ï¼Ÿ"):
                    st.session_state.continue_task = True
            if st.session_state.get("continue_task", False) and (st.markdown(
                    '<button class="custom-button">ğŸ§¹ å»é™¤æ°´å°</button>',
                    unsafe_allow_html=True
            ) or st.button("å»é™¤æ°´å°ï¼ˆå¤‡ç”¨ï¼‰")):
                st.session_state.cancel_task = False
                if st.markdown(
                        '<button class="custom-button cancel-button">âŒ å–æ¶ˆå¤„ç†</button>',
                        unsafe_allow_html=True
                ) or st.button("å–æ¶ˆå¤„ç†ï¼ˆå¤‡ç”¨ï¼‰"):
                    st.session_state.cancel_task = True
                if uploaded_file and canvas_result and canvas_result.image_data is not None:
                    try:
                        mask = canvas_result.image_data[:, :, 3].astype(np.uint8)
                        mask[mask > 0] = 255

                        if file_type == "å›¾åƒ":
                            image = cv2.imdecode(np.frombuffer(uploaded_file.read(), np.uint8), cv2.IMREAD_COLOR)
                            with st.spinner("å¤„ç†å›¾åƒ..."):
                                result = remove_watermark_image(image, mask, inpaint_radius)
                            st.image(result, caption="å»æ°´å°åçš„å›¾åƒ", channels="BGR", use_column_width=True)
                            output_file = os.path.join(output_path,
                                                       f"processed_image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")
                            cv2.imwrite(output_file, result)
                            st.download_button(
                                label="â¬‡ï¸ ä¸‹è½½å»æ°´å°å›¾åƒ",
                                data=open(output_file, "rb").read(),
                                file_name=os.path.basename(output_file),
                                mime="image/png"
                            )

                        elif file_type == "è§†é¢‘":
                            temp_path = os.path.join(upload_path, uploaded_file.name)
                            with open(temp_path, "wb") as f:
                                f.write(uploaded_file.read())
                            output_file = os.path.join(output_path,
                                                       f"processed_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
                            with st.spinner("å¤„ç†è§†é¢‘..."):
                                result = remove_watermark_video(temp_path, mask, output_file, inpaint_radius,
                                                                max_duration)
                            if result:
                                st.video(result)
                                st.download_button(
                                    label="â¬‡ï¸ ä¸‹è½½å»æ°´å°è§†é¢‘",
                                    data=open(result, "rb").read(),
                                    file_name=os.path.basename(result),
                                    mime="video/mp4"
                                )

                    except Exception as e:
                        st.error(f"å¤„ç†é”™è¯¯: {e}. è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–æ©ç æ˜¯å¦æ­£ç¡®ã€‚")
                else:
                    st.error("è¯·ä¸Šä¼ æ–‡ä»¶å¹¶ç»˜åˆ¶æ°´å°åŒºåŸŸï¼")
            st.markdown('</div>', unsafe_allow_html=True)

# é¡µè„š
st.markdown("---")
st.markdown(f"ğŸŒŸ è¿è¡Œäº {'GPU' if torch.cuda.is_available() else 'CPU'} | ä¸Šä¼ : {upload_path} | ä¿å­˜: {output_path}")
st.markdown("**æç¤º**ï¼šè¾“å…¥ä»»æ„æ—¶é•¿ï¼ˆå¦‚ 5.5 ç§’ï¼‰ï¼›ç™½è‰²ç”»ç¬”æ ‡è®°æ°´å°ï¼Œé»‘è‰²æ“¦é™¤ï¼›åŠ¨æ€æ°´å°éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")